## 性能测试与调优
主要是微观层面上的，最重要的是知道如何测量性能和把重点放在什么上面。

### 性能测试
单纯地算出运算事件是很低效的，不可信的。有很多其他因素会影响它。

#### 重复
不要自作聪明搞一个循环来测试性能。异常因素太多了。样本根本不是平均的。

#### Benchmark.js
统计学意义上的测试才是我们需要的。标准差、方差、误差幅度这些概念要有个了解。

* Benchmark.js是一个符合统计学的测试库，比如API有要测试的运算(函数)、测试名称、每秒运算数、出错边界、样本方差等等
* 还可以比较两个测试对象、在浏览器和node环境里测试、针对应用中JavaScript的关键路径部分运行自动性能回归测试。
* setup和teardown可以定义在每个测试之前和之后调用的函数，但不会在每个测试迭代都运行。

### 环境为王
如果这个性能差异对于人类来说根本没什么，就可以忽略了。所以++x和x++根本没什么必要争论。

#### 引擎优化
现代引擎会实现各种算法和技巧，根本不知道引擎对我们的代码进行了优化没有。

* 要测试就测试自己有把握的情况下的东西，不然就是假的。

### jsPerf.com
想要得到可靠的测试结论的话，要在pc、移动端、浏览器、node端等汇集测试结果。

* jsPerf是Benchmark.js的可视化版本

#### 完整性检查
不要自己写循环进去、声明和初始化可能是不必要的。

* 第一个例子函数和直接赋值的消耗是不同的
* 第二个例子因为自定义了函数本身就不公平,每个迭代都会声明函数
* 还有一个陷阱是隐式地给一个测试用例避免或添加额外的工作
* 如果两个测试用例结果都不同那就是扯淡。

### 写好测试
测试要能让别人看懂，最好有注释和文档

### 微性能
具体细节会影响性能？不存在的，引擎会做很多事情。

#### 不是所有的引擎都类似

* 人注意的应该是编写高阅读性的代码，至于性能引擎会做好。
* 性能优化工作应该交给引擎，比如V8，不传递arguments变量，把try..catch分离到单独的函数里。
* 对于现在的优化技巧，要考虑未来的前景。谨慎hack。引擎问题应该委托给浏览器厂商。

#### 大局
过早优化是万恶之源。但关键路径上的优化是值得的。

* 可读性也应该考虑。

### 尾调用优化
尾调用就是一个出现在另一个函数“结尾”处的函数调用。通过栈帧来处理。

* TCO就是只使用一个栈帧优化递归，但是前提是必须是有尾调用的递归函数
* ES6特性而不是引擎特性
